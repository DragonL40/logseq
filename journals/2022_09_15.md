- https://ai.googleblog.com/2017/04/federated-learning-collaborative.html #[[Federated Learning]]
	- Federated Learning enables mobile phones to **collaboratively** learn a **shared** prediction model while keeping all the training data on device, decoupling the ability to do machine learning from the need to store the data in the cloud.
	- **Benefits**
		- Smarter models
		- Lower latency
		- Less power consumption
		- In addition to providing an update to the shared model, the improved 
		  id:: 6322d334-ab82-4b4b-91e8-8d818ec6c5cd
		  model on your phone can also be used **immediately**, powering experiences 
		  personalized by the way you use your phone.
	- **Challenges**
		- Bandwidth and latency limitation of the dataset split across millions of devices means that typical ML algorithms such as [[Stochastic Gradient Descent (SGD)]] will not work. This motivates their [[Federated Averaging]] algorithm.
			- As upload speeds are typically [much slower](http://www.speedtest.net/reports/united-states/) than download speeds, we also developed a novel way to reduce upload communication costs up to another 100x by [compressing updates](https://arxiv.org/abs/1610.05492) using random rotations and quantization.
			- While these approaches are focused on training deep networks, we've also [designed algorithms](https://arxiv.org/abs/1610.02527) for **high-dimensional sparse convex models** which excel on problems like click-through-rate prediction.
		- Federated Learning algorithms often requires computations to be performed on the user's device. Why should the user volunteer their device? Is there a [[Nash Equilibrium]]?
			- [Optimality and Stability in Federated Learning: A Game-theoretic Approach](https://papers.neurips.cc/paper/2021/file/09a5e2a11bea20817477e0b1dfe2cc21-Paper.pdf)
		-