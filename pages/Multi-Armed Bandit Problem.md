- > The multi-armed bandit problem is a classic reinforcement learning example where we are given a slot machine with $n$ arms (bandits) with each arm having its own *rigged* probability distribution of success. Pulling any one of the arms gives you a stochastic reward of either $R=1$ for success, or $R=0$ for failure. Our objective is to pull the arms one-by-one in sequence such that we maximize our total reward collected in the long run. [Anson Wong, Solving the Multi-Armed Bandit Problem](https://towardsdatascience.com/solving-the-multi-armed-bandit-problem-b72de40db97c)
- The non-triviality of the multi-armed bandit problem lies in the fact that we (the agent) cannot access the true bandit probability distributions.
  background-color:: #978626
-