source:: https://arxiv.org/pdf/2208.12242.pdf

- # Main Contributions
	- subject-driven generation
		- given a few casually captured images of a subject, the goal is to synthesize novel renditions of the subject in different contexts, while maintaining high fidelity to its key visual features.
	- A new technique for fine-tuning text-to-image diffusion models in a few-shot setting, while preserving the
	  modelâ€™s semantic knowledge on the class of the subject.